{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RL (Ch.01) Tic-tac-toe.ipynb","provenance":[],"collapsed_sections":["h4ZE4zFcFPGY","tFnZE9BgJhSt","zTb9QVCeK781","kSHjB2U9TbG_"],"authorship_tag":"ABX9TyOb+0Jqo3QfGvhiwF6ww9hK"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"SB5Jq_lUJdD1","colab_type":"text"},"source":["###***Introduction to Reinforcement Learning (Sutton)***\n","#Chapter 1: TIC-TAC-TOE\n","\n","[SOURCE](https://github.com/ShangtongZhang/reinforcement-learning-an-introduction/blob/master/chapter01/tic_tac_toe.py)\n","\n"]},{"cell_type":"code","metadata":{"id":"jYW0vU3JEw4J","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pickle"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zHygj3reE1TL","colab_type":"code","colab":{}},"source":["boardrows=3\n","boardcols=3\n","boardsize=boardrows*boardcols"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h4ZE4zFcFPGY","colab_type":"text"},"source":["### **(1) Creating the State Class**\n","* The board is represented by an n*n array\n","* ( 1) represents a chessman of the player who moves first\n","* (-1) represents a chessman of another player\n","* ( 0) represents an empty position"]},{"cell_type":"code","metadata":{"id":"DcN81RQNFFEC","colab_type":"code","colab":{}},"source":["class State:\n","  def __init__(self):\n","    #Matrix zero with the size of boardrows*boardcols\n","    self.data=np.zeros((boardrows,boardcols))\n","    self.winner=None\n","    self.hash_val=None\n","    self.end=None\n","\n","  #Computation of the hash value for one state, it's unique\n","  def hash(self):\n","    if self.hash_val is None:\n","      self.hash_val=0\n","      for i in np.nditer(self.data):\n","        self.hash_val=self.hash_val*3+i+1\n","    return self.hash_val\n","  \n","  #Checking whether a player has won the game, or it's a tie\n","  def is_end(self):\n","    if self.end is not None:\n","      return self.end\n","    result=[]\n","\n","    #Checking the row\n","    for i in range(boardrows):\n","      results.append(np.sum(self.data[i,:]))\n","    \n","    #Checking the column\n","    for i in range(boardcols):\n","      results.append(np.sum(self.data[:,i]))\n","    \n","    #Checking the diagonals\n","    trace=0\n","    reverse_trace=0\n","    for i in range(boardrows):\n","      trace+=self.data[i,i]\n","      reverse_trace+=self.data[i,boardrows-1-i]\n","    results.append(trace)\n","    results.append(reverse_trace)\n","\n","    for result in results:\n","      if result==3:\n","        self.winner=1\n","        self.end=True\n","        return self.end\n","      if result==-3:\n","        self.winner=-1\n","        self.end==True\n","        return self.end\n","    \n","    #Checking whether it's a tie\n","    sum_values=np.sum(np.abs(self.data))\n","    if sum_values==boardsize:\n","      self.winner=0\n","      self.end=True\n","      return self.end\n","    \n","    #Checking whether the game is still going on\n","    self.end=False\n","    return self.end\n","\n","  #@symbol: 1 or -1\n","  #Putting the chessman symbol in position (i,j)\n","  def next_state(self,i,j,symbol):\n","    new_state=State()\n","    new_state.data=np.copy(self.data)\n","    new_state.data[i,j]=symbol\n","    return new_state\n","  \n","  #Printing the board\n","  def print_state(self):\n","    for i in range(boardrows):\n","      print('-------------')\n","      out='| '\n","      for j in range(boardcols):\n","        if self.data[i,j]==1:\n","          token='*'\n","        elif self.data[i,j]==-1:\n","          token='x'\n","        else:\n","          token='o'\n","        out+=token+' | '\n","      print(out)\n","    print('-------------')\n","\n","def get_all_states():\n","  current_symbol=1\n","  current_state=State()\n","  all_states=dict()\n","  all_states[current_state.hash()]=(current_state,currenet_state.is_end())\n","  get_all_states_impl(current_state,current_symbol,all_states)\n","  return all_states"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LEZ9FCJ1I8EW","colab_type":"code","colab":{}},"source":["#All possible board configurations\n","all_states=get_all_states"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tFnZE9BgJhSt","colab_type":"text"},"source":["###**(2) Creating the Judger Class**\n","* @Player1: the player who will move first, its chessman will be 1\n","* @Player2: another player with a chessman -1"]},{"cell_type":"code","metadata":{"id":"ovI8F3ApJfKQ","colab_type":"code","colab":{}},"source":["class Judger:\n","  def __init__(self,player1,player2):\n","    self.p1=player1\n","    self.p2=player2\n","    self.current_player=None\n","    self.p1_symbol=1\n","    self.p2_symbol=-1\n","    self.p1.set_symbol(self.p1_symbol)\n","    self.p2.set_symbol(self.p2_symbol)\n","    self.current_state=State()\n","\n","  def reset(self):\n","    self.p1.reset()\n","    self.p2.reset()\n","\n","  def alternate(self):\n","    while True:\n","      yield self.p1\n","      yield self.p2\n","\n","  #@Print state: if TRUE, print each board during the game\n","  def play(self,print_state=False):\n","    alternator=self.alternate()\n","    self.reset()\n","    current_state=State()\n","    self.p1.set_state(current_state)\n","    self.p2.set_state(current_state)\n","    if print_state:\n","      current_state.print_state()\n","    while True:\n","      player=next(alternator)\n","      i,j,symbol=player.act()\n","      next_state_hash=current_state.next_state(i,j,symbol).hash()\n","      current_state,is_end=all_states[next_state_hash]\n","      self.p1.set_state(current_state)\n","      self.p2.set_state(current_state)\n","      if print_state:\n","        current_state.print_state()\n","      if is_end:\n","        return current_state.winner\n","                      "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zTb9QVCeK781","colab_type":"text"},"source":["###**(3) Creating the AI Player**\n","* @Step_size: the step size to update estimations\n","* @Epsilon: the probability to explore"]},{"cell_type":"code","metadata":{"id":"grkSfOH0LIF5","colab_type":"code","colab":{}},"source":["class Player:\n","  def __init__(self,step_size=0.1,epsilon=0.1):\n","    self.estimations=dict()\n","    self.step_size=step_size\n","    self.epsilon=epsilon\n","    self.states=[]\n","    self.greedy=[]\n","    self.symbol=0\n","  \n","  def reset(self):\n","    self.states=[]\n","    self.greedy=[]\n","  \n","  def set_state(self,state):\n","    self.states.append(state)\n","    self.greedy.append(True)\n","  \n","  def set_symbol(self,symbol):\n","    self.symbol=symbol\n","    for hash_val in all_states:\n","      state,is_end=all_states[hash_val]\n","      if is_end:\n","        if state.winner==self.symbol:\n","          self.estimations[hash_val]=1.0\n","        elif state.winner==0:\n","          #Distinguishing between tie and lose here:\n","          self.estimations[hash_val]=0.5\n","        else:\n","          self.estimations[hash_val]=0\n","      else:\n","        self.estimations[hash_val]=0.5\n","    \n","    #Updating value estimations\n","    def backup(self):\n","      states=[state.hash() for state in self.states]\n","\n","      for i in reversed(range(len(states)-1)):\n","        state=states[i]\n","        td_error=self.greedy[i]*(self.estimations[states[i+1]]-self.estimations[state])\n","        self.estimations[state]+=self.step_size*td_error\n","    \n","    #Choosing an action based on state\n","    def act(self):\n","      state=self.states[-1]\n","      next_states=[]\n","      next_positions=[]\n","      for i in range(boardrows):\n","        for j in range(boardcols):\n","          if state.data[i,j]==0:\n","            next_positions.append([i,j])\n","            next_states.append(state.next_state(i,j,self.symbol).hash())\n","      if np.random.rand()<self.epsilon:\n","        action=next_positions[np.random.randint(len(next_positions))]\n","        action.append(self.symbol)\n","        self.greedy[-1]=False\n","        return action\n","      \n","      values=[]\n","      for hash_val,pos in zip(next_states,next_positions):\n","        values.append((self.estimations[hash_val],pos))\n","      # Selecting one of the actions of equal value at random due to Python's sort is stable\n","      np.random.shuffle(values)\n","      values.sort(key=lambda x:x[0],reverse=True)\n","      action=values[0][1]\n","      action.append(self.symbol)\n","      return action\n","\n","    def save_policy(self):\n","      with open('policy_%s.bin' % ('first' if self.symbol==1 else 'second'), 'wb') as f:\n","        pickle.dump(self.estimations,f)\n","    \n","    def load_policy(self):\n","      with open('policy_%s.bin' % ('first' if self.symbol==1 else 'second'), 'rb') as f:\n","        self.estimations=pickle.load(f)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kSHjB2U9TbG_","colab_type":"text"},"source":["###**(4) Creating Human Interface**"]},{"cell_type":"code","metadata":{"id":"nQHYI_VETi1n","colab_type":"code","colab":{}},"source":["# human interface\n","# input a number to put a chessman\n","# | q | w | e |\n","# | a | s | d |\n","# | z | x | c |"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BQlMf1JdTkSX","colab_type":"code","colab":{}},"source":["class HumanPlayer:\n","  def __init__(self,**kwargs):\n","    self.symbol=None\n","    self.keys=['q','w','e','a','s','d','z','x','c']\n","    self.state=None\n","  \n","  def reset(self):\n","    pass\n","\n","  def set_state(self,state):\n","    self.state=state\n","  \n","  def set_symbol(self,symbol):\n","    self.symbol=symbol\n","  \n","  def act(self):\n","    self.state.print_state()\n","    key=input(\"INPUT YOUR POSITION:\")\n","    data=self.keys.index(key)\n","    i=data//boardcols\n","    j=data%boardcols\n","    return i,j,self.symbol\n","\n","def train(epochs,print_every_n=500):\n","  player1=Player(epsilon=0.01)\n","  player2=Player(epsilon=0.01)\n","  judger=Judger(player1,player2)\n","  player1_win=0.0\n","  player2_win=0.0\n","  for i in range(1,epochs+1):\n","    winner=judger.play(print_state=False)\n","    if winner==1:\n","      player1_win+=1\n","    if winner==-1:\n","      player2_win+=1\n","    if i % print_every_n==0:\n","      print('Epoch %d, player 1 winrate: %.02f, player 2 winrate: %.02f' % (i,player1_win/i,player2_win/i))\n","    player1.backup()\n","    player2.backup()\n","    judger.reset()\n","  player1.save_policy()\n","  player2.save_policy()\n","\n","def compete(turns):\n","  player1=Player(epsilon=0)\n","  player2=Player(epsilon=0)\n","  judger=Judger(player1,player2)\n","  player1.load_policy()\n","  player2.load_policy()\n","  player1_win=0.0\n","  player2_win=0.0\n","  for _ in range(turns):\n","    winner=judger.play()\n","    if winner==1:\n","      player1_win+=1\n","    if winner==-1:\n","      player2_win+=1\n","    judger.reset()\n","  print('%d turns, player 1 win %.02f, player 2 win %.02f' % (turns,player1_win/turns,player2_win/turns))\n","\n","# The game is a zero sum game. If both players are playing with an optimal strategy, every game will end in a tie.\n","# So, we test whether the AI can guarantee at least a tie if it goes second.\n","def play():\n","  while True:\n","    player1=HumanPlayer()\n","    player2=Player(epsilon=0)\n","    judger=Judger(player1,player2)\n","    player2.load_policy()\n","    winner=judger.play()\n","    if winner==player2.symbol:\n","      print(\"You lose!\")\n","    elif winner==player1.symbol:\n","      print(\"You win!\")\n","    else:\n","      print(\"It is a tie!\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"awff7yfkVn9g","colab_type":"code","colab":{}},"source":["if __name__ == '__main__':\n","  train(int(0.00001))\n","  compete(int(0.001))\n","  play()"],"execution_count":null,"outputs":[]}]}